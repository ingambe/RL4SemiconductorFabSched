import argparse
import os
import random
import sys
import math
import cloudpickle
from datetime import datetime
from typing import List

import numpy as np
import torch
import wandb
from torch import nn

from simulation.classes import Lot
from simulation.dispatching.dispatcher import Dispatchers
from simulation.file_instance import FileInstance
from simulation.greedy import build_batch
from simulation.instance import Instance
from simulation.plugins.cost_plugin import PierreCostPlugin
from simulation.randomizer import Randomizer
from simulation.read import read_all
from simulation.stats import print_statistics


def _center_function(population_size):
    centers = np.arange(0, population_size, dtype=np.float32)
    centers = centers / (population_size - 1)
    centers -= 0.5
    return centers


def _compute_ranks(rewards):
    rewards = np.array(rewards)
    ranks = np.empty(rewards.size, dtype=int)
    ranks[rewards.argsort()] = np.arange(rewards.size)
    return ranks


def rank_transformation(rewards):
    ranks = _compute_ranks(rewards)
    values = _center_function(rewards.size)
    return values[ranks]


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.0))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)


def init_weights(m, std=math.sqrt(2)):
    torch.nn.init.orthogonal_(m.weight, std)
    if m.bias is not None:
        torch.nn.init.constant_(m.bias, 0)
    return m


class PositionalEncoding(nn.Module):
    def __init__(self, embedding_len, imput_dim):
        super(PositionalEncoding, self).__init__()
        self.embedding = nn.Parameter(torch.zeros(embedding_len, imput_dim))
        trunc_normal_(self.embedding, std=0.02)

    def forward(self, x, i):
        x = x + self.embedding[i]
        return x


class SelfSupervision(nn.Module):
    def __init__(self, imput_dim, embedding_len):
        super(SelfSupervision, self).__init__()
        self.embedding = PositionalEncoding(embedding_len, imput_dim)
        self.attention_head = nn.MultiheadAttention(
            imput_dim, 1, bias=False, batch_first=True
        )
        self.output = nn.Linear(imput_dim, embedding_len)
        torch.nn.init.xavier_normal_(self.output.weight)

    def forward(self, x, i):
        x = self.embedding(x, i)
        x = x.unsqueeze(0)
        x, _ = self.attention_head.forward(x, x, x, need_weights=False)
        x = x.squeeze(0)
        return self.output(x)


class SecondNet(nn.Module):
    def __init__(self, imput_dim):
        super(SecondNet, self).__init__()
        self.first_attention_head = nn.MultiheadAttention(
            imput_dim, 2, bias=False, add_bias_kv=False, batch_first=True
        )
        # self.first_attention_head.in_proj_weight.data = torch.randn_like(self.first_attention_head.in_proj_weight.data)
        # self.first_attention_head.in_proj_weight.data *= 1.0 / torch.sqrt(
        #    torch.square(self.first_attention_head.in_proj_weight.data).sum(dim=0, keepdim=True))
        # self.first_attention_head.out_proj = init_weights(self.first_attention_head.out_proj)
        self.linear = nn.Sequential(
            init_weights(nn.Linear(imput_dim * 2, 16)),
            nn.Tanh(),
            init_weights(nn.Linear(16, 16)),
            nn.Tanh(),
            init_weights(nn.Linear(16, 1, bias=False), std=0.01),
        )

    def forward(self, x, x_init):
        x_init = x
        x = x.unsqueeze(0)
        x, _ = self.first_attention_head.forward(x, x, x, need_weights=False)
        x = x.squeeze(0)
        x = torch.cat((x, x_init), dim=1)
        return self.linear(x)


class Normalizer(nn.Module):
    def __init__(self, imput_dim):
        super(Normalizer, self).__init__()
        self.mean = nn.Parameter(torch.zeros((imput_dim,), dtype=torch.float))
        self.std = nn.Parameter(torch.zeros((imput_dim,), dtype=torch.float))

    def forward(self, x):
        return (x - self.mean) / (self.std + 1e-3)


class Network(nn.Module):
    def __init__(self, imput_dim, embedding_len):
        super(Network, self).__init__()
        self.normalizer = Normalizer(imput_dim)
        self.embedding = PositionalEncoding(embedding_len, imput_dim)
        self.inner_net = SecondNet(imput_dim)

    def forward(self, x_init, i):
        x_init = self.normalizer(x_init)
        x = self.embedding(x_init, i)
        return self.inner_net(x, x_init)


def get_lot_priority(
    lots: List,
    instance: Instance,
    current_time: int,
    tools_type: list,
    neural_net: nn.Module,
):
    with torch.no_grad():
        percent_processed = []
        left_to_deadline = []
        total_waiting = []
        waiting_last_step = []
        lot_to_lens = []
        priorities = []
        remaining_times = []
        min_setup_times = []
        current_op_mean = []
        nb_machine_set_up = []
        min_batching = []
        max_batching = []
        tools_type_required = []

        # used to store the type of tool needed
        free_tools_type = []
        for lot in lots:
            percent_processed.append(
                (lot.full_time - lot.remaining_time) / lot.full_time
            )
            left_to_deadline.append(lot.deadline_at - current_time)
            total_waiting.append(lot.waiting_time)
            waiting_last_step.append(current_time - lot.free_since)
            lot_to_lens.append(len(lot.dedications))
            priorities.append(lot.priority)
            remaining_times.append(lot.remaining_time)
            current_op_mean.append(lot.actual_step.processing_time.avg())
            min_setup_time = float("inf")
            tmp_nb = 0
            if lot.actual_step.setup_needed != "":
                for machine in lot.waiting_machines:
                    if machine.current_setup != lot.actual_step.setup_needed:
                        if lot.actual_step.setup_time is not None:
                            min_setup_time = min(
                                min_setup_time, lot.actual_step.setup_time
                            )
                        elif (
                            machine.current_setup,
                            lot.actual_step.setup_needed,
                        ) in instance.setups:
                            min_setup_time = min(
                                min_setup_time,
                                instance.setups[
                                    (
                                        machine.current_setup,
                                        lot.actual_step.setup_needed,
                                    )
                                ],
                            )
                        elif ("", lot.actual_step.setup_needed) in instance.setups:
                            min_setup_time = min(
                                min_setup_time,
                                instance.setups[("", lot.actual_step.setup_needed)],
                            )
                        else:
                            min_setup_time = 0
                    else:
                        tmp_nb += 1
                        min_setup_time = 0
            else:
                min_setup_time = 0
                tmp_nb = len(lot.waiting_machines)

            min_setup_times.append(min_setup_time)
            min_batching.append(lot.actual_step.batch_min)
            max_batching.append(lot.actual_step.batch_max)
            # matrix dedication
            free_tools_type.append(lot.waiting_machines[0].group)
            nb_machine_set_up.append(tmp_nb)
            tools_type_required.append(lot.actual_step.family)

        percent_processed = torch.FloatTensor(percent_processed).reshape(-1, 1)
        left_to_deadline = torch.FloatTensor(left_to_deadline).reshape(-1, 1)
        total_waiting = torch.FloatTensor(total_waiting).reshape(-1, 1)
        waiting_last_step = torch.FloatTensor(waiting_last_step).reshape(-1, 1)
        lot_to_lens = torch.FloatTensor(lot_to_lens).reshape(-1, 1)
        priorities = torch.FloatTensor(priorities).reshape(-1, 1)
        remaining_times = torch.FloatTensor(remaining_times).reshape(-1, 1)
        min_setup_times = torch.FloatTensor(min_setup_times).reshape(-1, 1)
        current_op_mean = torch.FloatTensor(current_op_mean).reshape(-1, 1)
        nb_machine_set_up = torch.FloatTensor(nb_machine_set_up).reshape(-1, 1)
        min_batching = torch.FloatTensor(min_batching).reshape(-1, 1)
        max_batching = torch.FloatTensor(max_batching).reshape(-1, 1)
        lots_rep = torch.hstack(
            (
                percent_processed,
                left_to_deadline,
                total_waiting,
                waiting_last_step,
                lot_to_lens,
                priorities,
                remaining_times,
                min_setup_times,
                current_op_mean,
                nb_machine_set_up,
                min_batching,
                max_batching,
            )
        )
        free_tools_type = [
            tools_type.index(x)
            if not x.startswith("Delay_")
            else tools_type.index("Delay")
            for x in free_tools_type
        ]
        """
        matrix_machine = torch.eye(len(lots), dtype=torch.bool)
        tools_type_required = np.array(tools_type_required)
        uniques, count_tools = np.unique(tools_type_required, return_counts=True)
        if len(uniques) < len(tools_type_required):
            for unique_tool, count_tool in zip(uniques, count_tools):
                if count_tool > 1:
                    idxs = np.where(tools_type_required == unique_tool)[0]
                    for i in idxs:
                        matrix_machine[i, idxs] = True
        """

        priority_jobs = neural_net(lots_rep, torch.LongTensor(free_tools_type)).view(-1)
        return priority_jobs


def get_lots_to_dispatch_by_lot(
    instance, current_time, tools_type: list, net: nn.Module, last_sort_time
):
    if last_sort_time != current_time:
        if len(instance.usable_lots) > 1:
            priority_jobs = get_lot_priority(instance.usable_lots, instance, current_time, tools_type, net)
            for lot, associated_priority in zip(instance.usable_lots, priority_jobs):
                lot.ptuple = (
                    0 if lot.cqt_waiting is not None else 1,
                    -lot.priority,
                    associated_priority
                )
            instance.usable_lots.sort(key=lambda k: k.ptuple)
        last_sort_time = current_time
    lots = instance.usable_lots
    min_set_time_for_machine = float('inf')
    setup_machine, setup_batch = None, None
    min_run_break_machine, min_run_break_batch = None, None
    family_lock = None
    for i in range(len(lots)):
        lot: Lot = lots[i]
        if family_lock is None or family_lock == lot.actual_step.family:
            family_lock = lot.actual_step.family
            if lot.actual_step.setup_needed == '':
                most_waiting_machine_no_setup = (-1, float('inf'))
                most_waiting_machine = (-1, float('inf'))
                for machine_index, machine in enumerate(lot.waiting_machines):
                    if machine.current_setup == '':
                        if most_waiting_machine_no_setup[1] > machine.free_since:
                            most_waiting_machine_no_setup = (machine_index, machine.free_since)
                        if most_waiting_machine[1] > machine.free_since:
                            most_waiting_machine = (machine_index, machine.free_since)
                if most_waiting_machine_no_setup[0] != -1:
                    return lot.waiting_machines[most_waiting_machine_no_setup[0]], build_batch(lot, lots[i + 1:]), last_sort_time
                else:
                    return lot.waiting_machines[most_waiting_machine[0]], build_batch(lot, lots[i + 1:]), last_sort_time
            else:
                for machine in lot.waiting_machines:
                    if lot.actual_step.setup_needed == machine.current_setup:
                        return machine, build_batch(lot, lots[i + 1:]), last_sort_time
                    else:
                        setup_time_for_machine = Dispatchers.get_setup(lot.actual_step.setup_needed, machine, lot.actual_step.setup_time, instance.setups)
                        if setup_machine is None:
                            setup_machine = machine
                            setup_batch = i
                        if machine.min_runs_left is None:
                            if min_set_time_for_machine > setup_time_for_machine:
                                min_set_time_for_machine = setup_time_for_machine
                                setup_machine = machine
                                setup_batch = i
    if setup_machine is not None:
        return (
            setup_machine,
            build_batch(lots[setup_batch], lots[setup_batch + 1 :]),
            last_sort_time,
        )
    return (
        min_run_break_machine,
        build_batch(lots[min_run_break_batch], lots[min_run_break_batch + 1 :]),
        last_sort_time,
    )


def one_pop_iter(instance: FileInstance, run_to: int, tools_type: list, net: nn.Module):
    with torch.no_grad():
        Randomizer().random.seed(0)
        net = torch.jit.script(net)
        last_sort_time = -1
        while not instance.done:
            done = instance.next_decision_point()
            instance.print_progress_in_days()
            if done or instance.current_time > run_to:
                break
            machine, lots, last_sort_time = get_lots_to_dispatch_by_lot(
                instance, instance.current_time, tools_type, net, last_sort_time
            )
            if lots is None:
                instance.usable_lots.clear()
                instance.lot_in_usable.clear()
                instance.next_step()
            else:
                instance.dispatch(machine, lots)
        instance.finalize()
        return instance.plugins[0].get_output_value()


def main():
    p = argparse.ArgumentParser()
    p.add_argument("--dataset", type=str, default="HVLM")
    p.add_argument("--days", type=int, default=365 + 365)
    p.add_argument("--wandb", action="store_true", default=True)
    a = p.parse_args()

    sys.stderr.write(f"Loading {a.dataset} for es greedy {a.days} \n")
    sys.stderr.flush()

    start_time = datetime.now()
    files = read_all("../../datasets/SMT2020_" + a.dataset.upper())

    run_to = 3600 * 24 * a.days
    Randomizer().random.seed(0)

    random.seed(0)
    os.environ["PYTHONHASHSEED"] = str(0)
    np.random.seed(0)
    torch.manual_seed(0)
    torch.cuda.manual_seed(0)
    torch.cuda.manual_seed_all(0)
    torch.backends.cudnn.deterministic = True

    # TODO change with previous cost fn
    plugins = [PierreCostPlugin()]

    if a.wandb:
        from simulation.plugins.wandb_plugin import WandBPlugin

        plugins.append(WandBPlugin())
    # master_instance = FileInstance(files, run_to, False, plugins)
    with open("365days_HVLM.pkl", mode="rb") as file:
        master_instance = cloudpickle.load(file, fix_imports=True)
        master_instance.plugins = plugins
        for plugin in plugins:
            plugin.on_sim_init(master_instance)
    # TODO save and add <UNK>
    tools_type = list(
        set(
            [
                x.group if not x.group.startswith("Delay_") else "Delay"
                for x in master_instance.machines
            ]
        )
    )
    # tools_type.append('<UNK>')
    print(tools_type)
    tools_type.sort()
    master_neural_net = Network(12, len(tools_type))
    master_neural_net.load_state_dict(torch.load("pretrained.pt"))
    wandb.save("pretrained.pt")
    master_neural_net.eval()
    one_pop_iter(master_instance, run_to, tools_type, master_neural_net)
    interval = datetime.now() - start_time
    print(master_instance.current_time_days, " days simulated in ", interval)
    print(master_instance.plugins[0].get_output_value())
    print_statistics(
        master_instance, a.days, a.dataset, "es", method="es_greedy_seed_0", dir="../es"
    )


if __name__ == "__main__":
    main()
